import streamlit as st
import os

# ìŠ¤íŠ¸ë¦¼ë¦¿ ê¸ˆê³ (.streamlit/secrets.toml)ì—ì„œ í‚¤ë¥¼ êº¼ë‚´ì„œ í™˜ê²½ë³€ìˆ˜ì— ì„¸íŒ…í•©ë‹ˆë‹¤.
# ì´ë ‡ê²Œ í•˜ë©´ LangChain ë‚´ë¶€ì˜ OpenAI ê´€ë ¨ ëª¨ë“ˆë“¤ì´ ì•Œì•„ì„œ ì´ í‚¤ë¥¼ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# AI í•µì‹¬ ë‘ë‡Œ ì—­í• ì„ í•˜ëŠ” ë¡œì§ íŒŒì¼ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤. (UI ì½”ë“œ 0ì¤„)
import bot_logic

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="í•œ-ë¯¸ í†µí•© ê·œì • AI ë¹„ì„œ", page_icon="âœˆï¸", layout="centered")

st.title("âœˆï¸ ë˜‘ë˜‘í•œ ê³µí•­/ì„¸ê´€ AI ë¹„ì„œ")
st.markdown("""
ì´ ì±—ë´‡ì€ **í•œêµ­ì˜ ê³µê³µë°ì´í„°(í‘œ í˜•ì‹)**ì™€ **ë¯¸êµ­ CBP/TSA ê·œì •(Q&A í˜•ì‹)**ì´  
í•˜ë‚˜ì˜ í†µì¼ëœ ìŠ¤í‚¤ë§ˆë¡œ ì •ê·œí™”(ETL)ëœ RAG íŒŒì´í”„ë¼ì¸ ìœ„ì—ì„œ ë™ì‘í•©ë‹ˆë‹¤.
""")

# --- ì„¸ì…˜ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ë³´ê´€) ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- DB ë° ëª¨ë¸ ìºì‹± ---
# @st.cache_resource ì¥ì‹ìë¥¼ ì‚¬ìš©í•˜ë©´, ìŠ¤íŠ¸ë¦¼ë¦¿ì´ í™”ë©´ì„ ìƒˆë¡œê³ ì¹¨í•  ë•Œë§ˆë‹¤ ë¬´ê±°ìš´ DBë‚˜ ì²´ì¸ì„ ë‹¤ì‹œ ë¡œë“œí•˜ì§€ ì•Šê³  ë©”ëª¨ë¦¬ì—ì„œ êº¼ë‚´ì˜µë‹ˆë‹¤.
@st.cache_resource 
def init_rag_system():
    # 1. ë²¡í„° DB ë¡œë“œ
    db = bot_logic.load_vector_db()
    # 2. ë¶„ì„/ë‹µë³€ ëª¨ë¸ ë¡œë“œ
    query_analyzer, qa_chain = bot_logic.load_ai_models()
    return db, query_analyzer, qa_chain

try:
    vectorstore, query_analyzer, qa_chain = init_rag_system()
except Exception as e:
    st.error("RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. DB ê²½ë¡œ ë° Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- UI: ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ í™”ë©´ì— ë¿Œë¦¬ê¸° ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- ë©”ì¸ ì±„íŒ… ë¡œì§ ---
if prompt := st.chat_input("ì˜ˆ: ì»µë¼ë©´(ìœ¡ë¥˜ìŠ¤í”„ ë‚´ì¥) ë¯¸êµ­ ê°ˆ ë•Œ ìœ„íƒìœ¼ë¡œ ë¶€ì³ë„ ë˜ë‚˜ìš”?"):
    
    # 1. ì‚¬ìš©ì ì§ˆë¬¸ í™”ë©´ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. AI ë´‡ ë‹µë³€ ìƒì„± ì˜ì—­
    with st.chat_message("assistant"):
        with st.status("ğŸ” ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  ê·œì •ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
            
            st.write("1ï¸âƒ£ ì§ˆë¬¸ ì˜ë„ íŒŒì•… ì¤‘...")
            # UIëŠ” ëª¨ë¥´ëŠ” ë³µì¡í•œ ë¶„ì„ì„ bot_logicì—ê²Œ ì™¸ì£¼ì¤ë‹ˆë‹¤.
            intent = bot_logic.analyze_intent(prompt, query_analyzer)
            st.write(f"ğŸ“ *íŒŒì•…ëœ ì˜ë„: ëª©ì ì§€='{intent.target_country}', ìˆ˜í•˜ë¬¼í˜•íƒœ='{intent.transport_method}', í•µì‹¬í‚¤ì›Œë“œ='{intent.item_name}'*")
            
            st.write("2ï¸âƒ£ í•„í„°ê°€ ê²°í•©ëœ ë‹¨ì¼ ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
            # ë¬¸ì„œë¥¼ ì°¾ì•„ì˜¤ëŠ” ì‹¬ë¶€ë¦„ë„ bot_logicì´ ëŒ€ì‹ í•©ë‹ˆë‹¤.
            docs = bot_logic.retrieve_documents(prompt, intent, vectorstore)
            
            if not docs:
                status.update(label="âš ï¸ ê´€ë ¨ëœ ê·œì •ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", state="error")
                st.stop()
                
            st.write("3ï¸âƒ£ ë°œê²¬ëœ ê·œì •(í•œ/ë¯¸ í˜¼í•©):")
            for i, d in enumerate(docs, 1):
                st.caption(
                    f"ğŸ’¡ ë¬¸ì„œ {i}: {d.metadata.get('category')} | ì œí•œ: ê¸°ë‚´({d.metadata.get('carry_on')}), "
                    f"ìœ„íƒ({d.metadata.get('checked_baggage')}), ë¯¸êµ­ì…êµ­({d.metadata.get('us_customs_admissibility')})"
                )
            status.update(label="âœ… ê²€ìƒ‰ ì™„ë£Œ! ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.", state="complete", expanded=False)

        # 3. ì™„ì„±ëœ ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°(íƒ€ì´í•‘ íš¨ê³¼)ìœ¼ë¡œ í™”ë©´ì— ë¿Œë ¤ì¤ë‹ˆë‹¤.
        message_placeholder = st.empty()
        full_response = ""
        
        # ì‹¤ì œ LLM ìŠ¤íŠ¸ë¦¬ë°ë„ bot_logicì´ ë‹´ë‹¹
        for chunk in bot_logic.generate_answer_stream(prompt, docs, qa_chain):
            full_response += chunk
            message_placeholder.markdown(full_response + "â–Œ")
        
        message_placeholder.markdown(full_response)
        
        # ë§ˆì§€ë§‰ìœ¼ë¡œ ë´‡ì˜ ë‹µë³€ì„ ì„¸ì…˜ì— ì €ì¥
        st.session_state.messages.append({"role": "assistant", "content": full_response})
